{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b95da5-48bd-46a8-8c33-2b5ab83481f3",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:24px;\">       机器学习大作业————肺部X光图像分类（是否为肺结核）</h1>\n",
    "\n",
    "**任务类型**：基于sklearn中四种机器学习算法（KNN，SVM，决策树，随机森林），两种深度学习架构（resneXt50，VIT）的肺部X光二分类任务（是否为肺结核样本）\n",
    "\n",
    "**数据来源**：https://www.kaggle.com/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset/data\n",
    "\n",
    "**数据量**：有标签的数据共4200张图片\n",
    "\n",
    "**训练设备**：4090D（24GB）\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812437a-b4a7-49e9-b078-86c547dd56e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.image as mpimg  # Matplotlib库中的image模块，用于图像处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf1fe7c-5396-4f63-b41f-c7a3246252aa",
   "metadata": {},
   "source": [
    "展示部分数据\n",
    "\n",
    "随机选择和显示正常胸部X光图像数据集中的样本，有助于检查和验证图像数据的质量和内容。\n",
    "\n",
    "通过可视化样本图像，可以直观地了解数据集的情况，为后续的数据处理和模型训练做好准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2774f867-20b9-4176-b9ad-b4cdce3bae1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# 设置图形大小，宽度为20，高度为20\n",
    "plt.figure(figsize=(20,20))\n",
    "# 指定正常胸部X光图像的文件夹路径\n",
    "folder=r'TB_Chest_Radiography_Database/Normal'\n",
    "# 随机选择并显示5张正常胸部X光图像\n",
    "for i in range(5):\n",
    "    file = random.choice(os.listdir(folder))\n",
    "    image_path= os.path.join(folder, file)\n",
    "    img=mpimg.imread(image_path)\n",
    "    ax=plt.subplot(1,5,i+1)\n",
    "    ax.title.set_text(file)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f93f39-550a-4928-9939-d05cd1ca8712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#同上方法查看部分肺结核样本\n",
    "import random\n",
    "plt.figure(figsize=(20,20))\n",
    "folder=r'TB_Chest_Radiography_Database/Tuberculosis'\n",
    "for i in range(5):\n",
    "    file = random.choice(os.listdir(folder))\n",
    "    image_path= os.path.join(folder, file)\n",
    "    img=mpimg.imread(image_path)\n",
    "    ax=plt.subplot(1,5,i+1)\n",
    "    ax.title.set_text(file)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34f4270-5351-40e2-84cb-d326f3faf6fb",
   "metadata": {},
   "source": [
    "机器学习部分，直接调包，无需自己搭模型\n",
    "\n",
    "数据读入与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75c9e29-636c-4a1b-88ad-b3e167e92aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义类别列表\n",
    "Categories = [\"Normal\",\"Tuberculosis\"]\n",
    "# 初始化用于存储图像数据和平铺图像数据的列表\n",
    "flat_data_arr = []\n",
    "target_arr = []\n",
    "datadir = \"TB_Chest_Radiography_Database/\"\n",
    "# 遍历每个类别\n",
    "for category in Categories:\n",
    "    print(f\"正在加载类别：{category}\")\n",
    "    path = os.path.join(datadir, category)\n",
    "    for img in os.listdir(path):\n",
    "        try:\n",
    "            img_path = os.path.join(path, img)\n",
    "              # 读取图像文件\n",
    "            img_array = imread(img_path, plugin='imageio')\n",
    "            # 调整图像大小为150x150，并保留3个颜色通道（RGB）\n",
    "            img_resized = resize(img_array, (150, 150, 3), anti_aliasing=True)\n",
    "              # 将调整大小后的图像展平并添加到数据列表中\n",
    "            flat_data_arr.append(img_resized.flatten())\n",
    "             # 将类别索引添加到目标列表中\n",
    "            target_arr.append(Categories.index(category))\n",
    "               # 捕捉并打印可能发生的异常\n",
    "        except Exception as e:\n",
    "            print(\"\")\n",
    "    print(f\"已加载类别 {category}\")\n",
    "# 将平铺的图像数据和目标数据转换为NumPy数组\n",
    "flat_data_arr = np.array(flat_data_arr)\n",
    "target_arr = np.array(target_arr)\n",
    "# 打印加载完成的消息\n",
    "print(\"所有类别图片已加载完成。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c906edf0-9f50-4ed4-9ea7-25b5f2751ba4",
   "metadata": {},
   "source": [
    "展示部分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2030aab-65bd-4049-bcb8-7009477270bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将平铺的图像数据和目标数据转换为NumPy数组\n",
    "flat_data = np.array(flat_data_arr)\n",
    "target = np.array(target_arr)\n",
    "# 创建一个DataFrame，将平铺的图像数据存储在DataFrame中\n",
    "df = pd.DataFrame(flat_data)\n",
    "# 添加目标标签列\n",
    "df[\"Target\"] = target\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861ed3bc-5ffe-4390-b9de-0bb9f4ad9117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop('Target',axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b2b666-919b-4cbb-9761-a8bc2595b539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y = df[['Target']]\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca4006-effb-4410-85c5-35426c696e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "#导入支持向量机（Support Vector Machine，SVM）模型，用于分类任务。\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#导入K最近邻（K-Nearest Neighbors，KNN）分类器，用于分类任务。\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#导入决策树（Decision Tree）分类器，用于分类任务。\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#：导入随机森林（Random Forest）分类器，用于分类任务。\n",
    "from sklearn.model_selection import train_test_split\n",
    "#导入用于将数据集拆分为训练集和测试集的函数 train_test_split。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae4390-acd6-4cee-8601-a6bb34e28a61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20002d-9234-47d0-9673-2be2ae93527a",
   "metadata": {},
   "source": [
    "综合考虑到运行时间等因素，用于限制训练集和测试集的大小，将它们分别截取前 700 个样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a76da-59f8-4853-8ebc-7e1508745567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train[:700]\n",
    "y_train = y_train[:700]\n",
    "X_test = X_test[:700]\n",
    "y_test = y_test[:700]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48035295-c5a3-49d6-92c4-4d43eb9f2046",
   "metadata": {},
   "source": [
    "支持向量机法分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90263ec1-e663-405a-933b-544e98209d84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 初始化支持向量机分类器，并设置probability=True以便启用概率估计\n",
    "svc = svm.SVC(probability=True)\n",
    "# 使用训练集X_train和y_train训练SVM模型\n",
    "svc.fit(X_train, y_train)\n",
    "# 计算SVM模型在测试集X_test上的准确性，并输出\n",
    "print(f\"SUPPORT VECTOR MACHINE ACCURACY: {svc.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307316eb-08c3-4664-8ade-f478817c2ce7",
   "metadata": {},
   "source": [
    "### 支持向量机（SVM）模型在测试集上的性能分析\n",
    "\n",
    "#### 准确性\n",
    "- **值**：96.43%\n",
    "- **含义**：这意味着模型在测试集上对输入数据进行分类时，96.43%的样本被正确分类。\n",
    "\n",
    "### 模型性能分析\n",
    "\n",
    "#### 高准确性\n",
    "- **表现**：SVM模型在测试集上表现出了较高的准确性，说明模型能够很好地学习训练数据的特征，并且能够有效地应用到新的测试数据上。\n",
    "\n",
    "#### 模型性能良好\n",
    "- **结论**：96.43%的准确性表明SVM模型在处理当前数据集时具有较强的预测能力，适合用于类似的分类任务。\n",
    "\n",
    "### 进一步优化\n",
    "- **建议**：虽然当前结果已经较好，但仍可以通过以下方法进一步提高模型性能：\n",
    "  - **调节模型参数**：例如调整核函数类型、正则化参数等。\n",
    "  - **增加数据量**：获取更多的训练数据以提升模型的泛化能力。\n",
    "  - **使用数据增强**：通过数据增强技术来增加训练数据的多样性，减少过拟合现象。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d621d11-34cc-431c-a95f-ef40aef6c643",
   "metadata": {},
   "source": [
    "使用训练好的支持向量机（SVM）模型 `svc` 对测试集数据 `X_test` 进行预测，返回预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08c14a7-8e4d-49da-9941-dcb18631f660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63daef1-3b0a-477d-859f-2b357742a9c1",
   "metadata": {},
   "source": [
    "模型预测输出的结果是一个数组，其中每个元素代表相应测试样本的预测标签。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2536147b-a075-4130-8a6e-5a178b65bd16",
   "metadata": {},
   "source": [
    "KNN法分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d9dfa0-e3b5-494e-85d0-6b89ae85a900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建KNN模型实例\n",
    "knn = KNeighborsClassifier()\n",
    "# 使用训练数据训练KNN模型\n",
    "knn.fit(X_train,y_train)\n",
    "# 输出KNN模型在测试集上的准确率\n",
    "print(f\" KNN  ACCURACY ：{knn.score(X_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d758bcb0-bde6-48d1-84fb-e270e286fd4a",
   "metadata": {},
   "source": [
    "这表明 KNN 模型在测试集上的准确率为 95.71%。该结果显示 KNN 模型在测试集上的表现较好，能够较为准确地分类大多数样本。与之前的 SVM 模型比较，SVM 的准确率为 96.43%，略高于 KNN 模型的表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d10b46-2b93-4544-8f33-1f05a6bb436f",
   "metadata": {},
   "source": [
    " 使用训练好的 KNN 模型对测试集 X_test 进行预测，返回预测标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd4d0b4-aabf-43aa-b6d4-6cbc672ae338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d94b7b-4e02-4ecc-9d68-7a8544dacc03",
   "metadata": {},
   "source": [
    "预测结果概述：\n",
    "\n",
    "数组中的每个值对应于一个测试样本的预测标签。\n",
    "预测标签为 0 表示模型预测该样本为正常。\n",
    "预测标签为 1 表示模型预测该样本为肺结核。\n",
    "样本测情况：\n",
    "\n",
    "从图片中可以看到，预测结果包含大量的 0，这表明在测试集中有很多样本被预测为正常。\n",
    "也有一些 1，表示有部分样本被预测为肺结核。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a52eef1-b242-4893-a47c-532b430c2f77",
   "metadata": {},
   "source": [
    "决策树法分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b554ebf7-af78-4e0e-aea7-22177a9a13bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建决策树分类器的实例\n",
    "dt = DecisionTreeClassifier()\n",
    "# 用训练数据拟合决策树模型\n",
    "dt.fit(X_train,y_train)\n",
    "# 在测试集上评估模型的准确率并打印结果\n",
    "print(f\" Decision Tree accuracy {dt.score(X_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec76a85c-15ea-47dc-9cdf-a66740f5c3fe",
   "metadata": {},
   "source": [
    "### 准确率解释\n",
    "\n",
    "#### 准确率（Accuracy）\n",
    "- **定义**：准确率是指模型在测试集上正确分类的样本数占总样本数的比例。\n",
    "- **值**：0.9214285714285714\n",
    "- **含义**：表示在所有测试样本中，有 92.14% 的样本被正确分类。具体来说，如果测试集中有 100 个样本，其中大约 92 个样本被模型正确分类，其余 8 个样本被错误分类。\n",
    "\n",
    "### 性能评价\n",
    "\n",
    "- **总体表现**：这个准确率值表明决策树模型在当前数据集上的表现是相对不错的，能够较好地分类大部分样本。\n",
    "- **改进空间**：但仍然存在约 7.86% 的样本被错误分类，提示我们模型还有提升的空间。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323d16a5-d1fa-40cf-bb50-3a7ae7e6e8c5",
   "metadata": {},
   "source": [
    " 使用训练好的决策树模型对测试集 X_test 进行预测，返回预测标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52dc994-d4b6-4ac6-88d5-75125299377d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1de6ae-78a1-4ba9-bf8b-2aefb82d4267",
   "metadata": {},
   "source": [
    "从数组中可以看出，模型对大多数样本的预测是准确的，但具体的准确率和F1分数等评估指标已经在之前的分析中给出：\n",
    "\n",
    "决策树模型在测试集上的准确率为 0.9214285714285714。这意味着该模型在测试集上有大约92.14%的预测是正确的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb05c6c-3ca5-4645-94fc-8b459abf6415",
   "metadata": {},
   "source": [
    "随机森林法分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba20950-61e7-4e1c-9b55-756af959e62b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建随机森林分类器的实例\n",
    "rf = RandomForestClassifier()\n",
    "# 使用训练数据训练模型\n",
    "rf.fit(X_train,y_train)\n",
    "print(f\"Random Forest accuracy : {rf.score(X_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7158e0a-d4cf-474e-8046-6c7f65639ae7",
   "metadata": {},
   "source": [
    "### 结果分析\n",
    "\n",
    "#### 准确率\n",
    "- **值**：0.9628571428571429\n",
    "- **含义**：即约96.29%。这一结果表明，模型在绝大多数情况下能够正确预测测试样本的类别。\n",
    "\n",
    "### 模型性能\n",
    "- **表现**：随机森林模型在这次任务中表现优异，准确率接近96.29%。这表明该模型能够有效地处理分类任务，具有较高的预测准确性。\n",
    "\n",
    "### 模型优势\n",
    "- **集成学习**：随机森林通过集成多棵决策树的预测结果，减少了单个模型可能出现的过拟合问题，提高了模型的泛化能力。\n",
    "- **鲁棒性**：这种集成方法使得随机森林在处理不同类型的数据集时表现更加稳定和可靠。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ab8678-b1ed-48c2-a25e-a92c46eddb25",
   "metadata": {},
   "source": [
    " 使用训练好的随机森林模型对测试集 X_test 进行预测，返回预测标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73b1a83-9db8-4e5a-a914-530c0c959042",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9722cb-a495-4e4d-a02c-594bfaf468f6",
   "metadata": {},
   "source": [
    "数组中的每个值表示模型对相应样本的预测类别。这里，0 和 1 分别代表两种不同的分类结果（例如，0 代表正常，1 代表肺结核）。\n",
    "输出结果中的 0 和 1 的分布展示了模型对测试集样本的分类情况。根据模型的准确率（96.29%），大部分预测是准确的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cc8c17-57f8-4982-a070-ad7653b53f75",
   "metadata": {},
   "source": [
    "评估测试结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f6cc52-adbb-4c57-9165-e1a95c91e789",
   "metadata": {},
   "source": [
    "定义一个评估模型的函数，评估和比较四种机器学习算法（支持向量机SVM、K近邻KNN、决策树Decision Tree和随机森林Random Forest）的分类性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe7c4d-7980-4bae-9c05-4e208e47df17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "       # 使用模型预测测试集\n",
    "    y_pred = model.predict(X_test)\n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    # 计算加权平均的F1得分\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return accuracy, f1\n",
    "#分别评估四种模型\n",
    "accuracy_svm, f1_svm = evaluate_model(svc, X_test, y_test)\n",
    "accuracy_knn, f1_knn = evaluate_model(knn, X_test, y_test)\n",
    "accuracy_dt, f1_dt = evaluate_model(dt, X_test, y_test)\n",
    "accuracy_rf, f1_rf = evaluate_model(rf, X_test, y_test)\n",
    "# 输出各个模型的评估结果\n",
    "print(\"SVM Accuracy:\", accuracy_svm)\n",
    "print(\"SVM F1 Score:\", f1_svm)\n",
    "print(\"KNN Accuracy:\", accuracy_knn)\n",
    "print(\"KNN F1 Score:\", f1_knn)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_dt)\n",
    "print(\"Decision Tree F1 Score:\", f1_dt)\n",
    "print(\"Random Tree Accuracy:\", accuracy_rf)\n",
    "print(\"Random Tree F1 Score:\", f1_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45596f1c-91be-4447-8af4-ba8a444c9703",
   "metadata": {},
   "source": [
    "准确率和F1得分最高的模型：随机森林模型（Random Forest）和支持向量机（SVM）在测试集上的表现最好，两者的准确率和F1得分都达到了0.9643左右，表明这两种模型在分类任务中的表现非常优越。\n",
    "\n",
    "KNN模型表现较好：K近邻（KNN）模型的表现次之，准确率为0.9371，F1得分为0.9394，仍然表现出良好的分类能。\n",
    "\n",
    "决策树模型表现相对较差：决策树（Decision Tree）模型的表现略逊色，准确率为0.9214，F1得分为0.9213，尽管仍然较高，但相比其他三种模型略不足。\n",
    "\n",
    "综合评价\n",
    "在四种模型中，随机森林模型和支持向量机模型表现最佳。K近邻模型次之，而决策树模型表现相对较差。根据这些评估结果，可以选择随机森林模型或支持向量机模型作为最终的分类模型，以实现最佳的分类效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb442a9-0853-4b56-bd29-7ad8097e53bc",
   "metadata": {},
   "source": [
    "这段代码绘制每个模型的混淆矩阵热图，通过颜色深浅表示正确分类和错误分类的数量。通过绘制每个模型的混淆矩阵，能够直观地比较各个模型在分类任务中的表现，识别出分类准确和错误分类的具体情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff553a8-fcb4-4498-954f-173936fcd0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# 对所有模型进行预测\n",
    "svc_pred = svc.predict(X_test)\n",
    "knn_pred = knn.predict(X_test)\n",
    "dt_pred = dt.predict(X_test)\n",
    "rf_pred=rf.predict(X_test)\n",
    "\n",
    "# 为每个模型创建混淆矩阵\n",
    "svc_cm = confusion_matrix(y_test, svc_pred)\n",
    "knn_cm = confusion_matrix(y_test, knn_pred)\n",
    "dt_cm = confusion_matrix(y_test, dt_pred)\n",
    "rf_cm=confusion_matrix(y_test, rf_pred)\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.subplot(1, 4, 1)\n",
    "sns.heatmap(svc_cm, annot=True, fmt='d', cmap='Blues', xticklabels=Categories, yticklabels=Categories)\n",
    "plt.title('SVM ')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "sns.heatmap(knn_cm, annot=True, fmt='d', cmap='Blues', xticklabels=Categories, yticklabels=Categories)\n",
    "plt.title('KNN ')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "sns.heatmap(dt_cm, annot=True, fmt='d', cmap='Blues', xticklabels=Categories, yticklabels=Categories)\n",
    "plt.title('DF')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Blues', xticklabels=Categories, yticklabels=Categories)\n",
    "plt.title('RF')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75353764-f655-4a44-831e-5e97c39f4744",
   "metadata": {},
   "source": [
    "### 模型比较与分析\n",
    "\n",
    "#### 准确率与精确率表现\n",
    "- **最佳表现**：随机森林在准确率和精确率上均表现最佳。\n",
    "- **次佳表现**：SVM次之。\n",
    "- **相对较差**：KNN和决策树则表现相对较差。\n",
    "\n",
    "#### 错误分类分析\n",
    "\n",
    "**正常类别的错误分类**\n",
    "- **SVM和随机森林**：错误分类最少，均为6。\n",
    "- **KNN和决策树**：错误分类较多，分别为8和24。\n",
    "\n",
    "**肺结核类别的错误分类**\n",
    "- **KNN**：错误分类最多，有39个错误分类，表现较差。\n",
    "- **决策树和SVM**：错误分类情况相同，均为32。\n",
    "\n",
    "#### 总体表现\n",
    "- **随机森林**：总体表现最好，在正常类别和肺结核类别的分类都相对准确。\n",
    "- **SVM**：在正常类别上的表现和随机森林相当，但在肺结核分类上稍差。\n",
    "- **决策树和KNN**：表现相对较差，特别是在肺结核分类上，KNN的错误分类数较多。\n",
    "\n",
    "### 结论\n",
    "综上所述，四种分类算法中：\n",
    "- **最佳选择**：随机森林的分类效果最佳，适用于需要高分类准确性的应用场景。\n",
    "- **次佳选择**：SVM表现稍逊于随机森林，但仍具备较好的分类能力。\n",
    "- **相对较差**：决策树和KNN的分类效果较差，特别是在处理肺结核分类任务时表现不佳。\n",
    "\n",
    "对于需要高分类准确性的应用场景，可以优先考虑使用随机森林算法。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0c1cd0-045f-4fdc-bd4b-fa61474f60f5",
   "metadata": {},
   "source": [
    "计算模型的ROC曲线及其对应的AUC值，并绘制出ROC曲线，以评估模型的分类性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d34595-67f8-46ef-a326-32fdfe16db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 为SVM获取预测概率\n",
    "svc_probs = svc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 为KNN获取预测概率\n",
    "knn_probs = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 决策树和随机森林通常返回概率，所以可以直接使用predict_proba\n",
    "dt_probs = dt.predict_proba(X_test)[:, 1]\n",
    "rf_probs = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 计算ROC曲线的FPR和TPR\n",
    "svc_fpr, svc_tpr, _ = roc_curve(y_test, svc_probs)\n",
    "knn_fpr, knn_tpr, _ = roc_curve(y_test, knn_probs)\n",
    "dt_fpr, dt_tpr, _ = roc_curve(y_test, dt_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "\n",
    "# 计算AUC\n",
    "svc_auc = auc(svc_fpr, svc_tpr)\n",
    "knn_auc = auc(knn_fpr, knn_tpr)\n",
    "dt_auc = auc(dt_fpr, dt_tpr)\n",
    "rf_auc = auc(rf_fpr, rf_tpr)\n",
    "# 绘制ROC曲线\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.plot(svc_fpr, svc_tpr, label=f'SVM (AUC = {svc_auc:.2f})')\n",
    "plt.plot(knn_fpr, knn_tpr, label=f'KNN (AUC = {knn_auc:.2f})')\n",
    "plt.plot(dt_fpr, dt_tpr, label=f'Decision Tree (AUC = {dt_auc:.2f})')\n",
    "plt.plot(rf_fpr, rf_tpr, label=f'Random Forest (AUC = {rf_auc:.2f})')\n",
    "\n",
    "# 绘制随机分类器的ROC曲线\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eeeddf-6650-408a-9203-6186ee5825f0",
   "metadata": {},
   "source": [
    "### 综合比较\n",
    "\n",
    "#### SVM\n",
    "- **AUC值**：最高（0.99）\n",
    "- **ROC曲线**：最接近理想状态，分类性能最佳。\n",
    "- **适用场景**：适用于高要求的分类任务，性能最佳。\n",
    "\n",
    "#### 随机森林\n",
    "- **AUC值**：次高（0.98）\n",
    "- **分类性能**：同样优异，仅次于SVM。\n",
    "- **适用场景**：综合性能优异，适用于大多数分类任务。\n",
    "\n",
    "#### KNN\n",
    "- **AUC值**：0.93\n",
    "- **分类性能**：整体表现良好，但在某些阈值下的表现不如SVM和随机森林。\n",
    "- **适用场景**：性能较好，但在处理复杂分类任务时可能不如前两者稳定。\n",
    "\n",
    "#### 决策树\n",
    "- **AUC值**：最低（0.90）\n",
    "- **分类性能**：相对较弱，需进一步优化。\n",
    "- **适用场景**：性能较弱，需进一步优化和改进。\n",
    "\n",
    "### 结论\n",
    "通过上述分析，可以确定：\n",
    "- **最佳选择**：SVM和随机森林是本次分类任务中的最佳选择，分别在准确性和稳定性上表现出色。\n",
    "  - **SVM**：适用于高要求的分类任务，性能最佳。\n",
    "  - **随机森林**：综合性能优异，适用于大多数分类任务。\n",
    "- **次佳选择**：KNN，性能较好，但在处理复杂分类任务时可能不如前两者稳定。\n",
    "- **进一步优化**：决策树，需进一步优化和改进以提升分类性能。\n",
    "\n",
    "### 综合表现总结\n",
    "- **SVM**：适用于高要求的分类任务，性能最佳。\n",
    "- **随机森林**：综合性能优异，适用于大多数分类任务。\n",
    "- **KNN**：性能较好，但在复杂分类任务上略逊一筹。\n",
    "- **决策树**：需进一步优化，当前分类性能最弱。\n",
    "\n",
    "在实际应用中，可以优先考虑SVM和随机森林算法，以实现更高的分类准确性和稳定性。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d649a493-667f-4bea-b174-7733fdf4c9f9",
   "metadata": {},
   "source": [
    "--------戴政部分2结束------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234c143a-3c9e-49b1-852e-ec7ad5852e47",
   "metadata": {},
   "source": [
    "--------陶四能部分开始------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceee64eb-8eb2-4df2-946b-4f2d895553c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch  # PyTorch库，用于深度学习的构建和训练\n",
    "import numpy as np  # NumPy库，用于数组和矩阵运算，提供了高效的数值计算工具\n",
    "from pathlib import Path  # Pathlib库，用于处理文件和目录路径\n",
    "import cv2  # OpenCV库，用于计算机视觉任务，如图像处理和视频处理\n",
    "import math  # 数学库，提供基础的数学函数和常量\n",
    "import pandas as pd  # Pandas库，用于数据分析和数据处理\n",
    "from skimage.transform import resize  # Scikit-Image库中的resize函数，用于图像缩放\n",
    "from skimage.io import imread  # Scikit-Image库中的imread函数，用于读取图像文件\n",
    "from sklearn.metrics import recall_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report  # Scikit-Learn库，用于计算评价指标和可视化混淆矩阵\n",
    "from collections.abc import Iterable  # Collections模块中的Iterable类，用于检查对象是否为可迭代对象\n",
    "import matplotlib.pyplot as plt  # Matplotlib库中的pyplot模块，用于数据可视化\n",
    "import os  # OS模块，用于操作系统相关功能，如文件和目录操作\n",
    "import timm  # PyTorch Image Models库，提供了大量预训练的视觉模型\n",
    "import torchvision  # Torchvision库，提供了用于计算机视觉的工具和预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc610ff-e341-4a53-90d1-16bc643fdd3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义批量大小为30\n",
    "batch_size = 30\n",
    "# 定义图像块的大小为16\n",
    "patch_size = 16\n",
    "# 定义输入图像的大小为224\n",
    "img_size = 224\n",
    "# 计算图像中块的数量（224x224的图像分成16x16的块）\n",
    "num_patches = (img_size // patch_size) ** 2\n",
    "# 定义位置嵌入的维度为768\n",
    "p_dim = 768\n",
    "# 定义自注意力头的数量为12\n",
    "heads_att = 12\n",
    "# 定义编码器的数量为12\n",
    "num_encoder = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb45c70-13cf-471f-8de4-2f794fb5f73b",
   "metadata": {},
   "source": [
    "数据处理阶段\n",
    "读取图像文件：使用 glob 方法从指定目录（\"TB_Chest_Radiography_Database/Normal/\" 和 \"TB_Chest_Radiography_Database/Tuberculosis/\"）中读取所有 PNG 格式的图像文件，并将这些文件路径转换为字符串格式存储。\n",
    "排序图像文件：通过 sorted() 函数对读取到的图像路径进行排序，确保数据的顺序一致，这对后续数据处理和模型训练的稳定性很重要。\n",
    "创建标签：为每个图像分配一个标签。对于正常的X光图像（Normal_images），分配标签 0；对于结核病的X光图像（TB_images），分配标签 1。这样做是为了在后续的机器学习模型中使用这些标签来训练识别正常和结核病图像的分类器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dbd567-920b-4390-9c0c-5584d1fa2f91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_class={0:\"Normal\",1:\"Tuberculosis\"}\n",
    "Normal_dir=Path(\"TB_Chest_Radiography_Database/Normal/\")\n",
    "TB_dir=Path(\"TB_Chest_Radiography_Database/Tuberculosis/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22156198-3b84-4bf2-b1ec-b0c4e7fc443d",
   "metadata": {},
   "source": [
    "使用glob方法匹配所有目标格式的文件并生成文件路径列表；通过 map 函数将路径对象转换为字符串，并使用 sorted 函数\n",
    "\n",
    "对路径列表进行排序，确保文件按字母顺序排列。\n",
    "\n",
    "为不同类别图像分配标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f098b94-4d93-4eab-bc35-c7e272227d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Normal_images:list=sorted(list(map(str, list(Normal_dir.glob(\"*.png\")))))\n",
    "TB_images:list=sorted(list(map(str, list(TB_dir.glob(\"*.png\")))))\n",
    "Normal_labels:list=[0]*len(Normal_images)\n",
    "TB_labels:list=[1]*len(TB_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e1298-f5cc-4e20-aed2-4e0df5bffaa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images=np.array(Normal_images+TB_images)\n",
    "labels=np.array(Normal_labels+TB_labels)\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92694a8d-bb50-455f-bfd5-128aa5f7fd08",
   "metadata": {},
   "source": [
    "运行结果显示 images 和 labels 数组的形状均为 (4200,)\n",
    "images 数组包含4200个元素，每个元素是一个图像文件的路径；labels 数组也包含4200个元素，每个元素是对应图像的标签。\n",
    "标签数组与图像路径数组的长度一致，确保每个图像有一个对应的标签。\n",
    "结果表明，正常胸部X光图像和结核病胸部X光图像的总数（即数据集）加起来是4200张。\n",
    "此运行结果验证了数据集中的图像和标签已正确读取并合并，每个图像都有一个对应的标签，并确保数据集大小和标签分配正确。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cde914-a08d-479b-bc5d-c91bb4c4ca6e",
   "metadata": {},
   "source": [
    "下面将图像路径和标签数据集分成训练集、验证集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def2e71b-d2f1-4943-bed4-68184edc8147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入train_test_split函数，用于划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 第一次划分：将数据集分成训练集(80%)和临时验证集(20%)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(images,labels,test_size=0.2,random_state=42)\n",
    "# 第二次划分：将临时验证集分成最终验证集(10%)和测试集(10%)\n",
    "x_valid,x_test,y_valid,y_test=train_test_split(x_valid,y_valid,test_size=0.5,random_state=42)\n",
    "\n",
    "(x_train.shape,x_valid.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be1740-36c8-4ec4-a39d-9da5a99d00ad",
   "metadata": {},
   "source": [
    "训练集 (x_train): 3360 个样本，用于训练模型。\n",
    "验证集 (x_valid): 420 个样本，用于训练期间的模型性能评估和参数调优\n",
    "测试集 (x_test): 420 个样本，用于最终模型性能评\n",
    "结果表明数据集已经按预期比例正确划分，每个子集的样本数与预期相符。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b9419a-cb88-4f19-aea1-1cfba62916cd",
   "metadata": {},
   "source": [
    "定义函数对输入的图像进行预处理，包括灰度转换、对比度增强、模糊处理、调整大小和颜色空间转换，并最终将图像的通道顺序调整为深度学习模型所需的格式\n",
    "其中利用自适应直方图均衡化 (CLAHE) 增强局部对比度，突出图像细节，防止过度增强；利用高斯模糊平滑图像，减少噪声和细节。\n",
    "将两者结合，改善图像质量，使后续处理和分析更有效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a0bb8f-9c84-428f-adda-cd49507acd27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_preprocessing(path):\n",
    "    img=cv2.imread(path)\n",
    "     # 将图像转换为灰度图像\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # 创建自适应直方图均衡化对象，clipLimit为对比度限制\n",
    "    clahe=cv2.createCLAHE(clipLimit=2)\n",
    "    # 应用自适应直方图均衡化\n",
    "    img=clahe.apply(img)\n",
    "    # 使用高斯模糊处理图像，内核大小为5x5\n",
    "    img=cv2.GaussianBlur(img,(5,5),0,borderType=cv2.BORDER_CONSTANT)\n",
    "    # 调整图像大小\n",
    "    img=cv2.resize(img,(img_size,img_size),interpolation=cv2.INTER_LINEAR)\n",
    "    # 将图像从灰度转换为RGB图像\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "    # 将图像的轴从 (height, width, channels) 转换为 (channels, height, width)\n",
    "    img=np.moveaxis(img,-1,0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b90d39-c56a-4c1c-a290-3e0619646385",
   "metadata": {},
   "source": [
    "对训练集、验证集和测试集中的所有图像进行预处理，并将它们转换为浮点型数组\n",
    "使用 map 函数对练集、验证集和测试集中的每个元素（图像路径）应用 image_preprocessing 函数，\n",
    "将处理后的图像列表转换为 NumPy 数组。\n",
    "使用 astype(np.float32) 将数组的数据类型转换为 32 位浮点型，以提高计算精度和兼容性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00327d-09db-4de6-8f12-83b5858060a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train=np.array(list(map(image_preprocessing,x_train))).astype(np.float32)\n",
    "x_valid=np.array(list(map(image_preprocessing,x_valid))).astype(np.float32)\n",
    "x_test=np.array(list(map(image_preprocessing,x_test))).astype(np.float32)\n",
    "x_train.shape,x_valid.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e87c82-5839-4446-9625-91f81fe8598f",
   "metadata": {},
   "source": [
    "将预处理后的图像数据和标签转换为 PyTorch 张量，并移动到指定的设备（CPU 或 GPU）上，以便进行后续的模型训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff6c94a-d26b-4094-b448-451a5897ad00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device=(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_train=torch.from_numpy(x_train).to(device)\n",
    "x_valid=torch.from_numpy(x_valid).to(device)\n",
    "x_test=torch.from_numpy(x_test).to(device)\n",
    "y_train=torch.from_numpy(y_train).to(device)\n",
    "y_valid=torch.from_numpy(y_valid).to(device)\n",
    "y_test=torch.from_numpy(y_test).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a3cd4-9651-409b-98af-6c0203501181",
   "metadata": {},
   "source": [
    "定义一个标准化处理类StandardScaler，用于对 PyTorch 张量进行标准化操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a408ccce-1bbc-48e0-9623-6cee048db242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StandardScaler():\n",
    "    def __init__(self) -> None:\n",
    "        # 初始化均值和标准差\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "\n",
    "    def fit(self, tensor: torch.Tensor) -> None:\n",
    "        # 计算并存储张量的均值和标准差\n",
    "        self.mean = tensor.mean((0, 2, 3), keepdim=True)\n",
    "        self.std = tensor.std((0, 2, 3), keepdim=True)\n",
    "\n",
    "    def transform(self, tensor: torch.Tensor) -> torch.Tensor:\n",
    "        # 使用计算得出的均值和标准差对张量进行标准化\n",
    "        scaled = (tensor - self.mean) / (self.std + 1e-5)\n",
    "        return scaled\n",
    "\n",
    "    def fit_transform(self, tensor: torch.Tensor) -> torch.Tensor:\n",
    "        # 计算均值和标准差，并对张量进行标准化\n",
    "        self.fit(tensor=tensor)\n",
    "        scaled = self.transform(tensor=tensor)\n",
    "        return scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e412a8de-ffa6-48e5-83e2-b2975aafa435",
   "metadata": {},
   "source": [
    "接着使用StandardScaler类对训练集、验证集和测试集的图像数据进行标准化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015dd306-417b-41b7-b4ad-c6c092993454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)\n",
    "x_valid=scaler.transform(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1915655c-f377-4b91-a0bc-30ed25f03522",
   "metadata": {},
   "source": [
    "从 torch.utils.data 模块导入 TensorDataset 和 DataLoader 两个类，以便将预处理后的数据集转换为 PyTorch 的数据集对象，并创建数据加载器以便于批量处理数据。\n",
    "TensorDataset 是一个将张量数据包装成数据集对象的类，可以将输入数据和标签打包在一起，便于数据加载和迭代。\n",
    "使用 TensorDataset 可以方便地将图像数据和标签结合起来，创建一个可迭代的数据集对象。\n",
    "DataLoader 是一个用于批量加载数据的类，可以从数据集对象中按批次加载数据，并提供对数据的随机访问、打乱和并行加载等功能。\n",
    "使用 DataLoader 可以方便地将数据集分成多个小批次，在训练过程中按批次加载数据，提高训练效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb3dc7b-3d6a-42df-b43c-1565ad4dedf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30631f49-b314-4bca-82ec-3fc96efd5adf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将训练集、验证集和测试集的图像数据和标签封装成 TensorDataset 对象\n",
    "train_dataset=TensorDataset(x_train,y_train)\n",
    "val_dataset=TensorDataset(x_valid,y_valid)\n",
    "test_dataset=TensorDataset(x_test,y_test)\n",
    "# 创建训练集、验证集和测试集的数据加载器，设置批量大小和是否打乱数据\n",
    "train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=False)\n",
    "val_loader=DataLoader(val_dataset,batch_size=batch_size,shuffle=False)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8230dcbd-c2a2-411b-8dba-c4ae4f1897e6",
   "metadata": {},
   "source": [
    "resnext50_32x4d 是 ResNeXt 网络架构的一种变体。ResNeXt 是一种卷积神经网络（CNN）架构，由 Facebook 的研究团队提出，它结合了 ResNet 和 Inception 模型的优点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d465437-cdc7-4b8a-bc49-f50325ab9c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base = torchvision.models.resnext50_32x4d(num_classes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd91ef-8c94-49de-ac54-631fafdce285",
   "metadata": {},
   "source": [
    "定义了一个自定义神经网络模型类 ResNext，继承自 torch.nn.Module。该模型在预训练的 base 模型基础上增加了一个 sigmoid 激活函数层，用于将模型输出转化为概率值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d58aa-5725-4834-b393-09ff1c95024a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNext(torch.nn.Module):\n",
    "    def __init__(self, base):\n",
    "        super().__init__()\n",
    "        self.base=base\n",
    "        self.sigmoid=torch.nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        return self.sigmoid(self.base(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440dc4cc-3d9e-4a87-842b-d54f606bf5c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=ResNext(base).to(device)\n",
    "print(model)  # 打印模型结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6e8a2-8696-43bc-8826-fbbcd835b925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 计算并打印模型的总参数数量\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efdd787-bb0d-4a37-b354-c3684fc6122a",
   "metadata": {},
   "source": [
    "模型的参数量为22981953"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6d760e-fcaa-4ccf-bcf3-847455ca785f",
   "metadata": {},
   "source": [
    "设置了训练模型的超参数和优化策略，包括训练的轮数、损失函数、优化器以及学习率调度器。它们将用于控制模型在训练过程中的行为。\n",
    "余弦退火学习率调度器会在训练过程中逐步调整学习率，以提高训练效果和模型性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203fc4d9-8ad2-4e31-a804-e0ca8f78bdeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 设置训练轮数\n",
    "epoch=100\n",
    "# 定义损失函数，使用二分类交叉熵损失函数\n",
    "loss_fn=torch.nn.BCELoss()\n",
    "# 定义优化器，使用随机梯度下降（SGD），学习率为 1e-3，动量为 0.9\n",
    "opt=torch.optim.SGD(model.parameters(),lr=1e-3,momentum=0.9)\n",
    "# 定义学习率调度器，使用余弦退火学习率调度器\n",
    "scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=opt,T_max=epoch,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5121903-a41d-4f95-8f5c-84ddc09e134f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_loss = float('inf')  # 初始化最优损失为正无穷\n",
    "best_model_weights = None  # 初始化最优模型权重\n",
    "patience = 10  # 早停策略的耐心值\n",
    "train_losses = []  # 用于存储每个epoch的训练损失\n",
    "val_losses = []  # 用于存储每个epoch的验证损失\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(f\"Epoch: {i+1}\\n\")\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    train_loss = 0  # 初始化训练损失\n",
    "    train_batches = len(train_loader)  # 获取训练批次数量\n",
    "    \n",
    "    # 训练循环\n",
    "    for batch, (x, y) in enumerate(train_loader):\n",
    "        pred = model(x).squeeze(-1)  # 模型预测\n",
    "        loss = loss_fn(pred, y.float())  # 计算损失\n",
    "        train_loss += loss.item()  # 累积损失\n",
    "        loss.backward()  # 反向传播\n",
    "        opt.step()  # 更新参数\n",
    "        opt.zero_grad()  # 清空梯度\n",
    "    \n",
    "    train_loss /= train_batches  # 计算平均训练损失\n",
    "    train_losses.append(train_loss)  # 记录训练损失\n",
    "    print(f\" \\n train loss: {train_loss:>8f} \\n\")\n",
    "    \n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    val_loss = 0  \n",
    "    val_batches = len(val_loader)  # 获取验证批次数量\n",
    "    \n",
    "    # 验证循环\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            pred = model(x).squeeze(-1)  # 模型预测\n",
    "            val_loss += loss_fn(pred, y.float()).item()  # 累积损失\n",
    "    \n",
    "    val_loss /= val_batches  # 计算平均验证损失\n",
    "    val_losses.append(val_loss)  # 记录验证损失\n",
    "    print(f\" \\n test loss: {val_loss:>8f} \\n\")\n",
    "    \n",
    "    # 检查是否为最优模型\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss  # 更新最优损失\n",
    "        best_model_weights = model.state_dict()  # 更新最优模型权重\n",
    "        patience = 10  #重置\n",
    "    else:\n",
    "        patience -= 1  \n",
    "        if patience == 0:  # 停止训练\n",
    "            break\n",
    "    \n",
    "    scheduler.step()  # 更新学习率\n",
    "\n",
    "# 加载最优模型权重\n",
    "model.load_state_dict(best_model_weights)\n",
    "print(f'best loss:', best_loss)\n",
    "print(\"ResNeXt训练结束--林家苏\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b83243-388d-4f99-826e-d91d6c41b11b",
   "metadata": {},
   "source": [
    "可视化观察模型在训练集和验证集上的损失变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a65e8-53fc-4b33-b96d-68e0a7b96b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 设置图形大小，宽度为 20 英寸，高度为 7 英寸\n",
    "plt.figure(figsize=(20, 7))\n",
    "# 绘制训练损失曲线\n",
    "# x 轴为训练的 epoch 数，y 轴为训练损失\n",
    "print(\"---ResneXt损失曲线--许海天---\")\n",
    "plt.plot(range(len(train_losses)), train_losses)\n",
    "# 绘制验证损失曲线\n",
    "# x 轴为训练的 epoch 数，y 轴为验证损失\n",
    "plt.plot(range(len(val_losses)), val_losses)\n",
    "# 添加图例，分别标记训练损失和验证损失曲线\n",
    "plt.legend(['loss', 'val_loss'], loc='upper right')\n",
    "# 显示绘制的图形\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9f48bf-d8dd-42f5-b021-ee0b22b8df63",
   "metadata": {},
   "source": [
    "### 结果分析\n",
    "\n",
    "#### 损失变化趋势\n",
    "- **初始阶段（0-2个epoch）**：验证损失波动较大，达到一个峰值后迅速下降。\n",
    "- **中期阶段（2-10个epoch）**：验证损失波动逐渐减小，但仍存在起伏。\n",
    "- **后期阶段（10-20个epoch）**：训练损失和验证损失均趋于稳定，验证损失略高于训练损失。\n",
    "\n",
    "#### 结论分析\n",
    "\n",
    "**模型收敛性**：\n",
    "- 训练损失持续下降，并在训练后期趋于稳定，表明模型在训练集上具有良好的收敛性。\n",
    "- 验证损失在初始阶段波动较大，但随后逐渐减小并趋于稳定，说明模型在验证集上的表现逐渐稳定。\n",
    "\n",
    "**验证损失波动**：\n",
    "- 初始阶段验证损失的波动较大，可能是由于模型在早期对数据的学习尚不稳定，或数据集存在噪声。\n",
    "- 中期阶段验证损失仍有起伏，但总体趋势在下降，表明模型在逐渐适应验证集的数据。\n",
    "\n",
    "**模型性能**：\n",
    "- ResNeXt模型最终训练损失和验证损失都达到较低值，表明模型在训练集和验证集上均有较好的表现。\n",
    "- 验证损失略高于训练损失，表明模型有一定的泛化能力，但仍需关注验证损失的波动情型在实际应用中的稳定性。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d69e1cc-1bde-4096-873c-ba91f0ea465d",
   "metadata": {},
   "source": [
    "在模型评估模式下，计算验证集和测试集的预测结果，并根据这些预测结果计算召回率和准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e047284d-b25f-445a-bf0c-a3b4e26e2033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#评估模型在验证集上的性能\n",
    "# 切换模型到评估模式\n",
    "model.eval()\n",
    "# 初始化用于存储验证集预测结果的列表\n",
    "val_preds=[]\n",
    "# 禁用梯度计算以节省内存和加速计算\n",
    "with torch.no_grad():\n",
    "    # 遍历验证数据加载器中的每一个批次\n",
    "    for x,y in val_loader:\n",
    "         # 使用模型进行预测，并移除最后一维（将输出的形状从 [batch_size, 1] 变为 [batch_size]）\n",
    "        pred=model(x).squeeze(-1)\n",
    "        # 将预测结果从 GPU 移动到 CPU，并转换为 numpy 数组，添加到 val_preds 列表中\n",
    "        val_preds.append(pred.cpu().numpy())\n",
    "        # 将列表中的所有批次预测结果拼接成一个 numpy 数组\n",
    "val_preds=np.concatenate(val_preds,axis=0)  \n",
    "# 对预测结果进行四舍五入，以得到二分类的最终预测结果（0 或 1）\n",
    "val_preds=np.round(val_preds)\n",
    "# 计算验证集的召回率和准确率\n",
    "recall_score(y_valid.cpu().numpy(),val_preds),accuracy_score(y_valid.cpu().numpy(),val_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeb7262-7b26-4277-8d35-6ea2abaa19f6",
   "metadata": {},
   "source": [
    "### 运行结果\n",
    "\n",
    "#### 召回率：0.9295774647878324\n",
    "- 这个指标表示在所有真实为正样本（1）的样本中，模型正确预测为正样本的比例。\n",
    "- 即模型能够正确识别大部分的正样本，但仍有一部分正样本被错误分类。\n",
    "\n",
    "#### 准确率：0.983333333333333\n",
    "- 这个指标表示在所有样本中，模型预测正确的样本比例。\n",
    "- 较高的准确率表明模型整体表现良好，绝大部分样本都被正确分类。\n",
    "\n",
    "#### 模型性能\n",
    "- **召回率和准确率都相对较高**，表明模型在验证集上具有良好的分类性能。\n",
    "- 由于召回率略低于准确率，模型可能在识别某些正样本时存在一定的误差。这可能需要进一步优化模型或调整分类阈值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728a524-4293-4efb-b8de-1ef2456cdcfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#评估模型在测试集上的性能\n",
    "model.eval()\n",
    "# 初始化存储测试集预测结果的列表\n",
    "test_preds = []\n",
    "# 禁用梯度计算，以减少内存消耗和计算开销\n",
    "with torch.no_grad():\n",
    "    # 遍历测试集数据加载器，生成预测结果\n",
    "    for x, y in test_loader:\n",
    "        # 模型预测，并去掉最后一个维度\n",
    "        pred = model(x).squeeze(-1)\n",
    "        # 将预测结果从 GPU 移动到 CPU，并转换为 numpy 数组\n",
    "        test_preds.append(pred.cpu().numpy())\n",
    "# 将所有批次的预测结果拼接成一个数组\n",
    "test_preds = np.concatenate(test_preds, axis=0)\n",
    "# 将预测结果进行四舍五入，得到二分类结果（0 或 1）\n",
    "test_preds = np.round(test_preds)\n",
    "#计算召回率和准确率\n",
    "recall_score(y_test.cpu().numpy(),test_preds),accuracy_score(y_test.cpu().numpy(),test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eee2649-6146-43d0-98f9-d8957a79867c",
   "metadata": {},
   "source": [
    "### 运行结果\n",
    "\n",
    "#### 召回率：0.9242424242424242\n",
    "- 这个指标表示在所有真实为正样本（1）的样本中，模型正确预测为正样本的比例。\n",
    "- 召回率略低，说明模型有一部分正样本被错误分类为负样本（0）。\n",
    "\n",
    "#### 准确率：0.9880952380952381\n",
    "- 这个指标表示在所有样本中，模型预测正确的样本比例。\n",
    "- 较高的准确率表明模型整体表现良好，绝大部分样本都被正确分类。\n",
    "\n",
    "#### 模型性能\n",
    "- **虽然准确率较高，但召回率略低**，表明模型在识别正样本时存在一些误差。\n",
    "- 这可能会在某些应用场景中（例如需要更高召回率的任务）带来问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6891be6-7c26-4976-b515-8cd5c0cb8d62",
   "metadata": {},
   "source": [
    "定义函数计算测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7375409e-5a15-49a5-89e4-78f1a42866ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluation_parametrics(name,y_val, y_pred):\n",
    "    print(\"\\n{}\\n\".format(name))  \n",
    "    # 打印分类报告，包括精确度、召回率、F1分数和支持度\n",
    "    print(classification_report(y_val, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf24578-6511-477f-98eb-200d3807222f",
   "metadata": {},
   "source": [
    "定义画混淆矩阵的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c94b3cc-ea0f-4cb1-8db4-73293a72c678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eva_ConfusionMatrixDisplay(name,y_val, y_pred):\n",
    "    cm_test = confusion_matrix(y_val, y_pred)\n",
    "    t1 = ConfusionMatrixDisplay(cm_test)    \n",
    "    print(\"\\n{}\\n\".format(name))\n",
    "    t1.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c12202-3cbc-4bb3-9300-2eda4d215763",
   "metadata": {},
   "source": [
    "调用 evaluation_parametrics 函数对验证集和测试集的预测结果进行评估，生成分类报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203fa5f1-c2af-47bf-bdcb-54af5a4df49d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation_parametrics(\"ResneXt50 验证集结果--许海天\", y_valid.cpu().numpy(), val_preds)\n",
    "evaluation_parametrics(\"ResneXt50 测试集结果--许海天\", y_test.cpu().numpy(), test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e5d1e2-fe7f-4077-9310-ee336941e56a",
   "metadata": {},
   "source": [
    "### 验证集结果\n",
    "\n",
    "#### Precision（精确率）\n",
    "- **类别0（正常）**：验证集的精确率为0.99，说明模型在预测正常样本时的准确率非常高。\n",
    "- **类别1（肺结核）**：验证集的精确率为0.97，表明模型在预测肺结核样本时的误报率较低。\n",
    "\n",
    "#### Recall（召回率）\n",
    "- **类别0（正常）**：验证集的召回率为0.99，说明模型能够正确识别出绝大多数正常样本。\n",
    "- **类别1（肺结核）**：验证集的召回率为0.93，表明模型在识别肺结核样本时有一定漏报。\n",
    "\n",
    "#### F1-score\n",
    "- **类别0（正常）**：验证集的F1-score为0.99，表明模型在正常样本上的综合表现非常好。\n",
    "- **类别1（肺结核）**：验证集的F1-score为0.95，表明模型在肺结核样本上的综合表现较好。\n",
    "\n",
    "#### Accuracy（准确率）\n",
    "- 验证集的准确率为0.98，说明模型在整体分类任务中的表现非常出色。\n",
    "\n",
    "#### Macro avg 和 weighted avg\n",
    "- **Macro avg**：0.98，说明模型在各类别上的表现均衡。\n",
    "- **Weighted avg**：0.98，进一步证明模型的整体表现非常优秀。\n",
    "\n",
    "### 测试结果\n",
    "\n",
    "#### Precision（精确率）\n",
    "- **类别0（正常）**：测试集的精确率为0.99，说明模型在预测正常样本时的准确率非常高。\n",
    "- **类别1（肺结核）**：测试集的精确率为1.00，表明模型在预测肺结核样本时几乎没有误报。\n",
    "\n",
    "#### Recall（召回率）\n",
    "- **类别0（正常）**：测试集的召回率为1.00，说明模型能够正确识别出所有正常样本。\n",
    "- **类别1（肺结核）**：测试集的召回率为0.92，表明模型在识别肺结核样本时有一定漏报，但整体表现仍然良好。\n",
    "\n",
    "#### F1-score\n",
    "- **类别0（正常）**：测试集的F1-score为0.99，表明模型在正常样本上的综合表现非常好。\n",
    "- **类别1（肺结核）**：测试集的F1-score为0.96，表明模型在肺结核样本上的综合表现较好。\n",
    "\n",
    "#### Accuracy（准确率）\n",
    "- 测试集的准确率为0.98，说明模型在实际应用中的分类效果非常好。\n",
    "\n",
    "#### Macro avg 和 weighted avg\n",
    "- **Macro avg**：0.98，说明模型在各类别上的表现均衡。\n",
    "- **Weighted avg**：0.98，进一步证明模型的整体表现非常优秀。\n",
    "\n",
    "### 结论\n",
    "综上所述，ResNeXt50模型在验证集和测试集上的表现非常出色。模型能够很好地识别出正常和肺结核样本，具有高精确率、高召回率和高F1-score。同时，测试集的准确率为0.98，表明模型在实际应用中的分类效果也非常好。这表明ResNeXt50模型能够有效地用于肺结核的检测和分类。\n",
    "分效果也非常好。这表明ResNeXt50模型能够有效地用于肺结核的检测和分类。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d34a05b-00c0-41cb-9180-16687eaab8ce",
   "metadata": {},
   "source": [
    "调用 eva_ConfusionMatrixDisplay 函数对验证集和测试集的预测结果进行评估，生成混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e630a7-64ec-4349-98ff-113fd6cf16e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eva_ConfusionMatrixDisplay(\"ResNeXt50 验证集混淆矩阵--许海天\", y_valid.cpu().numpy(), val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a44ec8-242c-4859-8b08-0fbc36a8b52a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eva_ConfusionMatrixDisplay(\"ResNeXt50 测试集混淆矩阵--许海天\", y_test.cpu().numpy(), test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ec40ce-12d9-4651-9f62-e9074c97e86e",
   "metadata": {},
   "source": [
    "### 混淆矩阵解读\n",
    "\n",
    "#### ResNeXt50 模型在验证集上的混淆矩阵\n",
    "- 真阳性 (True Positive)：347\n",
    "- 假阳性 (False Positive)：2\n",
    "- 假阴性 (False Negative)：5\n",
    "- 真阴性 (True Negative)：66\n",
    "\n",
    "#### ResNeXt50 模型在测试集上的混淆矩阵\n",
    "- 真阳性 (True Positive)：354\n",
    "- 假阳性 (False Positive)：0\n",
    "- 假阴性 (False Negative)：5\n",
    "- 真阴性 (True Negative)：61\n",
    "\n",
    "### 分析\n",
    "\n",
    "#### 1. 准确率和召回率\n",
    "\n",
    "**验证集**：\n",
    "- 模型在验证集上的表现非常好，大部分样本都被正确分类，假阳性和假阴性都较少。\n",
    "- 准确率和召回率都很高，说明模型在验证集上的学习效果良好。\n",
    "\n",
    "**测试集**：\n",
    "- 模型在测试集上的表现也非常好，准确率依然保持在高水平，但假阴性的数量略有增加。\n",
    "- 虽然假阳性为零，但假阴性的存在表明模型可能存在一定的过拟合现象。\n",
    "\n",
    "#### 2. 泛化能力\n",
    "- 模型在未见过的数据上的表现也非常优秀，说明ResNeXt50模型具有良好的泛化能力。\n",
    "- 但是，测试集上假阴性的增加表明模型可能需要进一步优化。\n",
    "\n",
    "### 结论\n",
    "- ResNeXt50模型在分类任务中的表现非常优秀，适用于肺结核的诊断任务。\n",
    "- 尽管模型在测试集上有些假阴性，但总体而言，模型的准确率和召回率都很高，具有良好的应用前景。\n",
    "- 通过进一步优化模型，可以进一步提升其在实际应用中的表现，提高在不同数据集上的稳定性。现。一步优化，以提高在不同数据集上的稳定性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dc3573-7691-4a26-b158-deb7b23b0af1",
   "metadata": {},
   "source": [
    "计算模型的ROC曲线及其对应的AUC值，并绘制出ROC曲线，以评估模型的分类性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc2d595-ac7a-4655-abf0-d0d5beb1af48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "# 计算ROC曲线的FPR和TPR\n",
    "fpr_val, tpr_val, _ = roc_curve(y_valid.cpu().numpy(), val_preds)\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test.cpu().numpy(), test_preds)\n",
    "\n",
    "# 计算AUC\n",
    "roc_auc_val = auc(fpr_val, tpr_val)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "# 绘制ROC曲线\n",
    "plt.figure()\n",
    "plt.plot(fpr_val, tpr_val, label=f'Validation ROC curve (AUC = {roc_auc_val:.2f})')\n",
    "plt.plot(fpr_test, tpr_test, label=f'Test ROC curve (AUC = {roc_auc_test:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # 随机分类器的ROC曲线\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962f94b7-d437-460d-b03b-00f871a0e11b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 图片内容\n",
    "- **蓝色曲线**：验证集上的ROC曲线\n",
    "- **橙色曲线**：测试集上的ROC曲线\n",
    "- **AUC值**：验证集和测试集的AUC均为0.96\n",
    "\n",
    "#### ROC曲线和AUC值解读\n",
    "\n",
    "**ROC曲线**：\n",
    "- ROC曲线表示模型的分类性能，曲线下方的面积越大，模型的性能越好。\n",
    "- 曲线从左下角（0,0）到右上角（1,1）的路径表示不同的阈值下，模型的真阳性率（True Positive Rate, TPR）和假阳性率（False Positive Rate, FPR）的变化情况。\n",
    "\n",
    "**AUC值**：\n",
    "- AUC（Area Under the Curve）值表示ROC曲线下的面积。\n",
    "- AUC值范围在0.5到1之间，值越接近1，模型的性能越好。\n",
    "- 验证集和测试集的AUC值均为0.96，表明模型在这两个数据集上的分类性能都非常优秀。\n",
    "\n",
    "#### 模型性能分析\n",
    "\n",
    "**高AUC值**：\n",
    "- 验证集和测试集上的AUC值均为0.96，表明模型在这两个数据集上都有很高的区分能力。\n",
    "- 高AUC值意味着模型在各种阈值下都能保持较高的真阳性率和较低的假阳性率。\n",
    "\n",
    "**一致的表现**：\n",
    "- 验证集和测试集的ROC曲线非常接近，表明模型的性能在不同数据集上都非常一致。\n",
    "- 这种一致性说明模型的泛化能力较好，能够在未见过的数据上保持良好的分类性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d451176-3546-4c78-a11b-7f7db5697195",
   "metadata": {},
   "source": [
    "VIT部分"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e0aecbb-938d-4240-82a1-e3065b1e0337",
   "metadata": {},
   "source": [
    "定义函数实现从输入张量中提取图像块的功能，主要步骤包括填充输入张量以确保边界完整，使用 unfold 方法提取滑动窗口图像块，并调整维度顺序和展平图像块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1869a9-7d6e-4380-bd18-61d190bf0f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_patches(x: torch.Tensor, kernel: int, stride: int = 1, dilation: int = 1):\n",
    "    # 获取输入张量的形状\n",
    "    b, c, h, w = x.shape\n",
    "    # 计算输出张量的高度和宽度\n",
    "    h2 = math.ceil(h / stride)\n",
    "    w2 = math.ceil(w / stride)\n",
    "    # 计算需要填充的行和列\n",
    "    pad_row = (h2 - 1) * stride + (kernel - 1) * dilation + 1 - h\n",
    "    pad_col = (w2 - 1) * stride + (kernel - 1) * dilation + 1 - w\n",
    "    # 填充输入张量\n",
    "    x = torch.nn.functional.pad(x, (pad_row // 2, pad_row - pad_row // 2, pad_col // 2, pad_col - pad_col // 2))\n",
    "    \n",
    "    # 提取图像块\n",
    "    patches = x.unfold(2, kernel, stride).unfold(3, kernel, stride)\n",
    "    # 调整张量维度顺序并展平图像块\n",
    "    patches = patches.permute(0, 2, 3, 1, 4, 5).contiguous()\n",
    "    patches = patches.view(*patches.size()[:3], -1)\n",
    "    \n",
    "    # 返回展平后的图像块\n",
    "    return patches.view(b, -1, patches.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383e5bd9-0574-407c-a27b-74aa7b63c144",
   "metadata": {},
   "source": [
    "定义get_positional_embeddings为用于生成位置嵌入的函数。\n",
    "通过使用正弦和余弦函数，这些嵌入向量在不同维度上具有不同的频率，使模型能够更好地捕捉序列中的顺序关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1501793-e632-4c7a-9e85-ff8d72ab0d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_embeddings(sequence_length: int, d: int):\n",
    "    # 初始化结果张量，大小为 (sequence_length, d)，初始值为 1\n",
    "    result = torch.ones(sequence_length, d)\n",
    "    \n",
    "    # 遍历序列长度和维度，计算位置嵌入\n",
    "    for i in range(sequence_length):\n",
    "        for j in range(d):\n",
    "            # 计算位置嵌入\n",
    "            result[i][j] = (\n",
    "                np.sin(i / (10000 ** (j / d)))\n",
    "                if j % 2 == 0\n",
    "                else np.cos(i / (10000 ** ((j - 1) / d)))\n",
    "            )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca9872-e021-4406-a80c-ad3276846c30",
   "metadata": {},
   "source": [
    "定义一个编码器块类，用于实现 Transformer 模型中的一个编码器层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1547a68-5934-4490-870b-6bebd5e98349",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(torch.nn.Module):\n",
    "    def __init__(self, projection_dim: int, num_heads: int, num_patches: int):\n",
    "        super().__init__()\n",
    "        # 初始化参数\n",
    "        self.projection_dim = projection_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.num_patches = num_patches\n",
    "        # 定义层归一化层\n",
    "        self.norm1 = torch.nn.LayerNorm(self.projection_dim)\n",
    "        self.norm2 = torch.nn.LayerNorm(self.projection_dim)\n",
    "        # 定义多头注意力层\n",
    "        self.attention = torch.nn.MultiheadAttention(self.projection_dim, self.num_heads, batch_first=True)\n",
    "        # 定义多层感知机（MLP）\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.projection_dim, self.projection_dim * 4),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(self.projection_dim * 4, self.projection_dim),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # 层归一化和多头注意力机制\n",
    "        x1 = self.norm1(x)\n",
    "        attention = self.attention(x1, x1, x1)[0]\n",
    "        x2 = attention + x\n",
    "        # 第二次层归一化和MLP\n",
    "        x3 = self.norm2(x2)\n",
    "        x3 = self.mlp(x3)\n",
    "        # 残差连接\n",
    "        out = x2 + x3\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6983bb9d-d105-49f9-ba98-c385708c35e3",
   "metadata": {},
   "source": [
    "定义一个视觉变换器（ViT）模型类，用于图像分类任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719e6892-15f7-4174-bb5c-782ab63b9836",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(torch.nn.Module):\n",
    "    def __init__(self, patch_size: int, num_patches: int, projection_dim: int, num_heads: int, num_encoder: int):\n",
    "        super().__init__()\n",
    "        # 初始化参数\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "        self.projection_dim = projection_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.num_encoder = num_encoder\n",
    "        # 计算输入维度（每个图像块的大小）\n",
    "        self.input_d = self.patch_size * self.patch_size * 3\n",
    "        # 定义线性层，将输入图像块投影到指定的维度\n",
    "        self.linear = torch.nn.Linear(self.input_d, self.projection_dim)\n",
    "        # 定义位置嵌入\n",
    "        self.embbeding = torch.nn.Parameter(\n",
    "            get_positional_embeddings(self.num_patches, self.projection_dim)\n",
    "        )\n",
    "        self.embbeding.requires_grad = False\n",
    "        # 定义一系列编码器块\n",
    "        self.blocks = torch.nn.ModuleList([\n",
    "            EncoderBlock(self.projection_dim, self.num_heads, self.num_patches) for _ in range(self.num_encoder)\n",
    "        ])\n",
    "        # 定义层归一化层\n",
    "        self.ln_out = torch.nn.LayerNorm(self.projection_dim)\n",
    "        # 定义输出层\n",
    "        self.out = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.projection_dim, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, images: torch.Tensor):\n",
    "        batch_size = images.size()[0]\n",
    "        # 提取图像块\n",
    "        x = extract_image_patches(images, self.patch_size, self.patch_size)\n",
    "        # 投影图像块到指定的维度\n",
    "        x = self.linear(x)\n",
    "        # 添加位置嵌入\n",
    "        pos_embed = self.embbeding.repeat(batch_size, 1, 1)\n",
    "        encoded = x + pos_embed\n",
    "        # 通过编码器块\n",
    "        for block in self.blocks:\n",
    "            encoded = block(encoded)\n",
    "        # 平均池化\n",
    "        rep = encoded.mean(dim=1)\n",
    "        rep = self.ln_out(rep)\n",
    "        # 通过输出层\n",
    "        output = self.out(rep)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49b1e3-c8f7-4b40-a5b6-81da6ec5962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ViT(patch_size=patch_size,\n",
    "          num_patches=num_patches,\n",
    "          projection_dim=p_dim,\n",
    "          num_heads=heads_att,\n",
    "          num_encoder=num_encoder).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4498abb6-9d10-468e-8d4a-4b8175b62851",
   "metadata": {},
   "source": [
    "VIT模型结构--张海峰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242cff1e-9f83-485a-a8d2-689b71b33b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_total_params = sum(p.numel() for p in model.parameters())\n",
    "vit_total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8801628d-0355-41ae-acd3-0beb4ef996ab",
   "metadata": {},
   "source": [
    "通过计算和分析 ViT 模型的参数总数，我们可以评估模型的复杂性和计算资源需求。\n",
    "ViT 模型的总参数数目为 85,797,889，表明该模型在处理和训练过程中需要大量计算资源"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5781ddc5-47d6-4365-a4d3-c1562f6490c8",
   "metadata": {},
   "source": [
    "设置了训练模型的超参数和优化策略，包括训练的轮数、损失函数、优化器以及学习率调度器。它们将用于控制模型在训练过程中的行为。\n",
    "余弦退火学习率调度器会在训练过程中逐步调整学习率，以提高训练效果和模型性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ec6e5-7486-4e68-86a4-0d50d34abdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=100\n",
    "loss_fn=torch.nn.BCELoss()\n",
    "opt=torch.optim.SGD(model.parameters(),lr=1e-3,momentum=0.9)\n",
    "scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=opt,T_max=epoch,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253103a1-b370-4777-9eee-f0773f8f4b3a",
   "metadata": {},
   "source": [
    "训练一个深度学习模型，并在训练过程中监控验证损失，使用早停机制来防止过度训练。\n",
    "代码包含了训练和验证两个阶段，并使用学习率调度器来动态调整学习率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51981e48-1228-417a-b452-6bef8b204eaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 初始化变量\n",
    "best_loss = float('inf')  # 设置最佳损失初始值为无穷大\n",
    "best_model_weights = None  # 用于存储最佳模型的权重\n",
    "patience = 10  # 耐心值，当验证损失不再改善时提前停止训练\n",
    "train_losses = []  # 记录每个epoch的训练损失\n",
    "val_losses = []  # 记录每个epoch的验证损失\n",
    "for i in range(epoch):  # 迭代训练\n",
    "    print(f\"Epoch: {i + 1}\\n\")\n",
    "    # 训练阶段\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    train_loss = 0  # 初始化训练损失\n",
    "    train_batches = len(train_loader)  # 获取训练数据的批次数\n",
    "    for batch, (x, y) in enumerate(train_loader):  # 遍历每个训练批次\n",
    "        pred = model(x).squeeze(-1)  # 进行预测，并去掉最后一个维度\n",
    "        loss = loss_fn(pred, y.float())  # 计算损失\n",
    "        train_loss += loss.item()  # 累积损失\n",
    "        loss.backward()  # 反向传播计算梯度\n",
    "        opt.step()  # 更新模型参数\n",
    "        opt.zero_grad()  # 清空梯度\n",
    "    train_loss /= train_batches  # 计算平均训练损失\n",
    "    train_losses.append(train_loss)  # 记录训练损失\n",
    "    print(f\" \\n train loss: {train_loss:.8f} \\n\")\n",
    "    # 验证阶段\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    val_loss = 0  # 初始化验证损失\n",
    "    val_batches = len(val_loader)  # 获取验证数据的批次数\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        for x, y in val_loader:  # 遍历每个验证批次\n",
    "            pred = model(x).squeeze(-1)  # 进行预测，并去掉最后一个维度\n",
    "            val_loss += loss_fn(pred, y.float()).item()  # 累积损失\n",
    "    val_loss /= val_batches  # 计算平均验证损失\n",
    "    val_losses.append(val_loss)  # 记录验证损失\n",
    "    print(f\"\\n test loss: {val_loss:.8f} \\n\")\n",
    "    # 检查验证损失是否改善\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss  # 更新最佳损失\n",
    "        best_model_weights = model.state_dict()  # 保存最佳模型的权重\n",
    "        patience = 10  # 重置耐心值\n",
    "    else:\n",
    "        patience -= 1  # 耐心值减1\n",
    "        if patience == 0:  # 当耐心值为0时，停止训练\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    # 学习率调度器更新\n",
    "    scheduler.step()\n",
    "# 加载验证损失最小的模型权重\n",
    "model.load_state_dict(best_model_weights)\n",
    "print(f'Best validation loss: {best_loss:.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac55b7-ce69-4ff9-bb88-25184319b6b4",
   "metadata": {},
   "source": [
    "通过 Matplotlib 库绘制训练损失和验证损失的曲线图，以可视化的方式展示模型训练过程中损失的变化趋势"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ed8507-1df9-497f-ba41-369a2d521bc7",
   "metadata": {},
   "source": [
    "可视化观察模型在训练集和验证集上的损失变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba46759-ac19-4d54-a7c8-27fdde4d1c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置图形大小，宽度为 20 英寸，高度为 7 英寸\n",
    "plt.figure(figsize=(20, 7))\n",
    "# 绘制训练损失曲线\n",
    "# x 轴为训练的 epoch 数，y 轴为训练损失\n",
    "print(\"---VIT训练损失曲线--许海天---\")\n",
    "plt.plot(range(len(train_losses)), train_losses)\n",
    "# 绘制验证损失曲线\n",
    "# x 轴为训练的 epoch 数，y 轴为验证损失\n",
    "plt.plot(range(len(val_losses)), val_losses)\n",
    "# 添加图例，分别标记训练损失和验证损失曲线\n",
    "plt.legend(['loss', 'val_loss'], loc='upper right')\n",
    "# 显示绘制的图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e867ce-505f-41e1-8d20-4c2622128ece",
   "metadata": {},
   "source": [
    "### 结果分析\n",
    "\n",
    "#### 初始阶段\n",
    "- 在训练初期（前3个epoch），训练损失和验证损失都较高，随后快速下降，表明模型在早期同样快速学习到数据的特征。\n",
    "\n",
    "#### 中期阶段\n",
    "- 训练损失持续下降，并在接近第15个epoch时达到较低值，随后继续缓慢下降，表明模型在训练集上的拟合效果逐渐提升。\n",
    "\n",
    "#### 验证损失波动\n",
    "- 验证损失在整个训练过程中波动较大，特别是在第15个epoch前后，波动明显。这可能是由于ViT模型对数据较为敏感，特别是在小数据集或存在噪声的情况下。\n",
    "\n",
    "#### 最终结果\n",
    "- 在训练结束时，训练损失较低且稳定，验证损失略高于训练损失，并且在最后几个epoch中仍存在一些波动。\n",
    "\n",
    "### 结论\n",
    "- ViT模型在训练过程中表现出良好的收敛性，训练损失显著下降。\n",
    "- 验证损失的较大波动可能反映出模型对数据敏感，可能需要更多的数据或进一步的数据增强来稳定模型的泛化性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a9ab8f-9ae4-4bc5-8c78-32bfa3993aa7",
   "metadata": {},
   "source": [
    "在模型评估模式下，计算验证集和测试集的预测结果，并根据这些预测结果计算召回率和准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d791c7-57d2-47d2-ad2b-39b0f844d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#评估验证集\n",
    "# 设置模型为评估模式，关闭 dropout 和 batch normalization\n",
    "model.eval()\n",
    "# 初始化存储验证集预测结果的列表\n",
    "val_preds = []\n",
    "# 禁用梯度计算，以减少内存消耗和计算开销\n",
    "with torch.no_grad():\n",
    "    # 遍历验证集数据加载器，生成预测结果\n",
    "    for x, y in val_loader:\n",
    "        # 模型预测，并去掉最后一个维度\n",
    "        pred = model(x).squeeze(-1)\n",
    "        # 将预测结果从 GPU 移动到 CPU，并转换为 numpy 数组\n",
    "        val_preds.append(pred.cpu().numpy())\n",
    "# 将所有批次的预测结果拼接成一个数组\n",
    "val_preds = np.concatenate(val_preds, axis=0)\n",
    "# 将预测结果进行四舍五入，得到二分类结果（0 或 1）\n",
    "val_preds = np.round(val_preds)\n",
    "#计算召回率和准确率\n",
    "recall_score(y_valid.cpu().numpy(),val_preds),accuracy_score(y_valid.cpu().numpy(),val_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b561ecae-2c5d-458c-bbfb-14ee0e86a486",
   "metadata": {},
   "source": [
    "### 运行结果\n",
    "\n",
    "#### 召回率 (Recall)\n",
    "- **值**：0.9859154929577465\n",
    "- **含义**：模型在验证集上的召回率为0.9859，说明模型能够正确识别出约98.59%的目标类样本。\n",
    "\n",
    "#### 准确率 (Accuracy)\n",
    "- **值**：0.9976190476190476\n",
    "- **含义**：模型在验证集上的准确率为0.9976，说明模型整体分类性能非常好，能够对约99.76%的样本进行正确分类。\n",
    "\n",
    "### 结论\n",
    "- **召回率**：模型在验证集上的召回率为0.9859，说明模型能够正确识别出绝大多数的目标类样本。\n",
    "- **准确率**：模型在验证集上的准确率为0.9976，表明模型在整体分类任务中表现非常出色，能够正确分类绝大多数样本。\n",
    "- **总体表现**：模型在验证集上的表现非常优秀，具有很高的召回率和准确率，表明模型在识别目标类样本和整体很好的表现。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd08955-0b47-4291-8182-64416439d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#评估测试集\n",
    "model.eval()\n",
    "# 初始化存储测试集预测结果的列表\n",
    "test_preds = []\n",
    "# 禁用梯度计算，以减少内存消耗和计算开销\n",
    "with torch.no_grad():\n",
    "    # 遍历测试集数据加载器，生成预测结果\n",
    "    for x, y in test_loader:\n",
    "        # 模型预测，并去掉最后一个维度\n",
    "        pred = model(x).squeeze(-1)\n",
    "        # 将预测结果从 GPU 移动到 CPU，并转换为 numpy 数组\n",
    "        test_preds.append(pred.cpu().numpy())\n",
    "# 将所有批次的预测结果拼接成一个数组\n",
    "test_preds = np.concatenate(test_preds, axis=0)\n",
    "# 将预测结果进行四舍五入，得到二分类结果（0 或 1）\n",
    "test_preds = np.round(test_preds)\n",
    "#计算召回率和准确率\n",
    "recall_score(y_test.cpu().numpy(),test_preds),accuracy_score(y_test.cpu().numpy(),test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55965f3-0a71-4f40-b98f-873cef0c0924",
   "metadata": {},
   "source": [
    "### 运行结果\n",
    "\n",
    "#### 召回率 (Recall)\n",
    "- **值**：0.9696969696969697\n",
    "- **含义**：模型在测试集上的召回率为0.9697，说明模型能够正确识别出约96.97%的目标类样本。\n",
    "\n",
    "#### 准确率 (Accuracy)\n",
    "- **值**：0.9952380952380953\n",
    "- **含义**：模型在测试集上的准确率为0.9952，说明模型整体分类性能非常好，能够对约99.52%的样本进行正确分类。\n",
    "\n",
    "### 结论\n",
    "- **召回率**：模型在测试集上的召回率为0.9697，说明模型能够正确识别出绝大多数的目标类样本。\n",
    "- **准确率**：模型在测试集上的准确率为0.9952，表明模型在整体分类任务中表现非常出色，能够正确分类绝大多数样本。\n",
    "- **总体表现**：模型在测试集上的表现非常优秀，具有很高的召回率和准确率，表明模型在识别目标类样本和整体分类任务中都有很好的表现。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec5f0ff-066e-4c5b-8b46-fcb022d8ae71",
   "metadata": {},
   "source": [
    "调用 evaluation_parametrics 函数对验证集和测试集的预测结果进行评估，生成分类报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f5ef13-29e6-49df-8f94-143ab72532e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_parametrics(\"VIT 验证集结果\", y_valid.cpu().numpy(), val_preds)\n",
    "evaluation_parametrics(\"VIT 测试集结果\", y_test.cpu().numpy(), test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4120830-562c-4200-a5b8-9a27fff7b709",
   "metadata": {},
   "source": [
    "### 验证集结果分析\n",
    "\n",
    "#### Precision（精确率）\n",
    "- **类别0（正常）**：精确率为1.00，表明模型在预测正常样本时没有误报。\n",
    "- **类别1（肺结核）**：精确率为1.00，表明模型在预测肺结核样本时没有误报。\n",
    "\n",
    "#### Recall（召回率）\n",
    "- **类别0（正常）**：召回率为1.00，表明模型能够正确识别所有正常样本。\n",
    "- **类别1（肺结核）**：召回率为0.99，表明模型在识别肺结核样本时略有漏报，但整体表现非常好。\n",
    "\n",
    "#### F1-score\n",
    "- **类别0（正常）**：F1-score为1.00，表明模型在正常样本上的表现完美。\n",
    "- **类别1（肺结核）**：F1-score为0.99，表明模型在肺结核样本上的综合表现非常好。\n",
    "\n",
    "#### Accuracy（准确率）\n",
    "- 验证集的准确率为1.00，表明模型在整体分类任务中的表现非常出色，几乎没有错误分类。\n",
    "\n",
    "#### Macro avg 和 weighted avg\n",
    "- 这两个指标分别是宏平均和加权平均，考虑了各类别的表现和支持度（样本数量）。验证集的macro avg和weighted avg在所有指标上的表现都为1.00，进一步说明模型的整体表现非常优秀。\n",
    "\n",
    "### 测试结果分析\n",
    "\n",
    "#### Precision（精确率）\n",
    "- **类别0（正常）**：精确率为0.99，表明模型在预测正常样本时有极少量误报。\n",
    "- **类别1（肺结核）**：精确率为1.00，表明模型在预测肺结核样本时没有误报。\n",
    "\n",
    "#### Recall（召回率）\n",
    "- **类别0（正常）**：召回率为1.00，表明模型能够正确识别所有正常样本。\n",
    "- **类别1（肺结核）**：召回率为0.97，表明模型在识别肺结核样本时略有漏报，但整体表现非常好。\n",
    "\n",
    "#### F1-score\n",
    "- **类别0（正常）**：F1-score为1.00，表明模型在正常样本上的表现完美。\n",
    "- **类别1（肺结核）**：F1-score为0.98，表明模型在肺结核样本上的综合表现非常好。\n",
    "\n",
    "#### Accuracy（准确率）\n",
    "- 测试集的准确率为1.00，表明模型在整体分类任务中的表现非常出色，几乎没有错误分类。\n",
    "\n",
    "#### Macro avg 和 weighted avg\n",
    "- 测试集的macro avg和weighted avg在所有指标上的表现都非常接近1.00，进一步说明模型的整体表现非常优秀。\n",
    "\n",
    "### 结论\n",
    "从结果来看，ViT模型在验证集和测试集上的表现都非常出色。模型能够很好地识别出正常和肺结核样本，具有高精确率、高召回率和高F1-score。同时，测试集的准确率为1.00，表明模型在实际应用中的分类效果也非常好。\n",
    "e。同时，测试集的准确率为1.00，表明模型在实际应用中的分类效果也非常好。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75348780-9b90-4c6a-975c-3c18097a2c64",
   "metadata": {},
   "source": [
    "调用 eva_ConfusionMatrixDisplay 函数对验证集和测试集的预测结果进行评估，生成混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f6077e-fa1e-422d-8244-6279c89ecda8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eva_ConfusionMatrixDisplay(\"VIT 验证集混淆矩阵\", y_valid.cpu().numpy(), val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e523953-bbfa-4877-acd8-1b194983a2ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eva_ConfusionMatrixDisplay(\"VIT 测试集混淆矩阵\", y_test.cpu().numpy(), test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b44fe6-9e58-4847-b9e3-ca870ead9a2b",
   "metadata": {},
   "source": [
    "### 验证集结论\n",
    "\n",
    "- **整体表现**：ViT 模型在验证集上的表现非常好，精度和召回率都很高，说明模型能够很好地学习到数据中的模式。\n",
    "- **不足之处**：对于少数的肺结核病例，有1个样本被误分类为正常。这说明在处理验证数据时，模型对少数类的表现略有不足。\n",
    "\n",
    "### 测试集结论\n",
    "\n",
    "- **整体表现**：ViT 模型在测试集上的表现依然很好，尤其是在精度上达到了1.00，这表明模型对正常样本的预测非常准确。\n",
    "- **不足之处**：对于肺结核样本，有2个样本被误分类为正常，这说明模型在处理实际数据时，对少数类的识别仍存在一些不足。\n",
    "\n",
    "### 总结\n",
    "\n",
    "- **总体表现**：ViT 模型在验证集和测试集上的总体表现都非常好，特别是在正常样本的分类上，几乎没有错误。\n",
    "- **改进建议**：唯一的改进点是提高对少数类（肺结核样本）的识别能力，可以考虑增加数据增强或使用更加平衡的损失函数来进一步优化模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0c6424-fe12-4f3e-95cd-dd317a4b679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "# 计算ROC曲线的FPR和TPR\n",
    "fpr_val, tpr_val, _ = roc_curve(y_valid.cpu().numpy(), val_preds)\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test.cpu().numpy(), test_preds)\n",
    "\n",
    "# 计算AUC\n",
    "roc_auc_val = auc(fpr_val, tpr_val)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "# 绘制ROC曲线\n",
    "plt.figure()\n",
    "plt.plot(fpr_val, tpr_val, label=f'Validation ROC curve (AUC = {roc_auc_val:.2f})')\n",
    "plt.plot(fpr_test, tpr_test, label=f'Test ROC curve (AUC = {roc_auc_test:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # 随机分类器的ROC曲线\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "print('----VIT roc曲线')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a77332f-c2a2-496e-a490-d455c6bba6d4",
   "metadata": {},
   "source": [
    "### 验证集 ROC 曲线\n",
    "- **蓝色曲线**：表示验证集上的 ROC 曲线，AUC 值为 0.99。这条曲线非常接近左上角，表明模型在验证集上的分类性能非常好，几乎能够完美地区分正常样本和肺结核样本。\n",
    "\n",
    "### 测试集 ROC 曲线\n",
    "- **橙色曲线**：表示测试集上的 ROC 曲线， AUC 值为 0.98。这条曲线同样非常接近左上角，表明模型在测试集上的分类性能也非常优秀，但略低于验证集的 AUC 值。\n",
    "\n",
    "### 结论\n",
    "\n",
    "#### 模型性能\n",
    "- **验证集和测试集 AUC 值**：ViT 模型在验证集和测试集上的 AUC 值分别为 0.99 和 0.98，表明该模型在两个数据集上的分类性能都非常优秀。AUC 值接近 1.0 表示模型具有很高的区分正负样本能力。\n",
    "\n",
    "#### 泛化能力\n",
    "- **ROC 曲线表现**：验证集和测试集上的 ROC 曲线表现非常接近，AUC 值差异很小。这表明模型在验证集上的优秀表现也能较好地泛化到未见过的测试集数据上，说明模型具有良好的泛化能力。\n",
    "\n",
    "#### 改进空间\n",
    "- **轻微过拟合**：尽管 AUC 值已经非常高，但测试集上的 AUC 值略低于验证集，说明模型在处理实际数据时可能存在一些轻微的过拟合。可以通过数据增强、正则化或调整模型结构等方法进一步优化模型，以减少这种差异。\n",
    "\n",
    "### 总结\n",
    "- **总体表现**：ViT 模型在肺结核检测任务中的表现非常优秀，特别是在正常样本和肺结核样本的区分上具有很高的准确性和可靠性。\n",
    "- **进一步提升**：为了进一步提升模型的性能，可以考虑使用更多的数据增强技术和模型调优策略，以确保模型在实际应用中的鲁棒性和泛化能力。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
